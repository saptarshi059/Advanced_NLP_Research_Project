{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21fy-AUmjR82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchtext.data import Field\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnwVBtkTkBYZ"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=lambda x: x.split(), lower=True) #spacy's performance is really good but it takes some time to execute.\n",
    "LABEL = Field(sequential=False, use_vocab=False) #set use_vocab = False when the data is already numerical.\n",
    "\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "datafields = [(\"id\", None),(\"conversation\",TEXT), (\"category\", LABEL)]\n",
    "\n",
    "#If skip_header is set to False, then the headers also get processed!\n",
    "trn = TabularDataset(path=\"train_custom.csv\", format='csv', skip_header=True, fields=datafields)\n",
    "tst = TabularDataset(path='test_custom.csv', format='csv', skip_header=True, fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvHtJCjV2bA0"
   },
   "outputs": [],
   "source": [
    "#Creating the vocabulary using GloVe embeddings.\n",
    "TEXT.build_vocab(trn, vectors=\"glove.6B.50d\")\n",
    "\n",
    "#print(TEXT.vocab.freqs.most_common(10))\n",
    "\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter = BucketIterator(\n",
    " dataset = trn, # we pass in the datasets we want the iterator to draw data from\n",
    " batch_size = 64,\n",
    " device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    " sort_key=lambda x: len(x.articles), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False, # we pass repeat=False because we want to wrap this Iterator layer.\n",
    " shuffle = False, #Experiment with this to see if you're getting improved performance.\n",
    " train = True #Whether the dataset is a training set or not.\n",
    " )\n",
    "\n",
    "test_iter = Iterator(tst, batch_size=64, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), \n",
    "                     sort=False, sort_within_batch=False, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "j4r0RrF_7BgO",
    "outputId": "91c7e4e3-27d7-4fc6-be71-16b61a24a929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<unk>\n",
      "(tensor([[  84,  151,   29,  ...,  807,   54,   72],\n",
      "        [   8,  173,   69,  ..., 1932,   63,   53],\n",
      "        [   6,  356, 1510,  ...,   66,    8,  489],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]]), tensor([4, 4, 4, 5, 2, 4, 5, 4, 4, 1, 5, 2, 2, 3]))\n"
     ]
    }
   ],
   "source": [
    "#Extra Code\n",
    "#print(trn[0].conversation)\n",
    "#print(TEXT.vocab.stoi) \n",
    "\n",
    "#print(len(train_iter)) # This gives the total number of batches.\n",
    "\n",
    "print(TEXT.vocab.stoi['<unk>'])\n",
    "print(TEXT.vocab.itos[0])\n",
    "for i in train_iter:\n",
    "  for j in i:\n",
    "    print(j)\n",
    "    break\n",
    "    if j != None:\n",
    "      print(j[0][:,0])\n",
    "      a = list(j[0][:,0]) # So, what I found out is that the articles are all located along the columns. So, each column is an article!\n",
    "      print(len(a))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "f8jv-ulRzXqr",
    "outputId": "e776f7cf-a670-42f7-a0fa-abbe61eb7a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10827, 64])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "class BatchWrapper:\n",
    "    #This takes care of the variable assignments.\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            '''\n",
    "            We use \"getattr\" here because we want to generalize our code. This function is similar to \"batch.conversation\". \n",
    "            But then we would need to change this line for different functions. getattr returns the value of an attribute of an object.\n",
    "            '''\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "            yield (x, y)\n",
    "\n",
    "    #This returns the number of batches.\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, \"conversation\", [\"category\"]) #(iterator, independent_variable, dependent_variable)\n",
    "test_dl = BatchWrapper(test_iter, \"conversation\", [\"category\"])\n",
    "\n",
    "for x,y in test_dl:\n",
    "  print(x.shape)\n",
    "  print(y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "o3FyX57XSG6e",
    "outputId": "14191599-a108-4b76-97c2-822e09afee80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierNet(\n",
      "  (embedding): EmbeddingBag(400000, 50, mode=mean)\n",
      "  (fc): Linear(in_features=50, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchtext\n",
    "\n",
    "class ClassifierNet(torch.nn.Module):\n",
    "    def __init__(self, glove, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.EmbeddingBag.from_pretrained(glove.vectors)\n",
    "        self.fc = torch.nn.Linear(glove.dim, num_class)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=50)    \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_classes = 6\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "net = ClassifierNet(glove, num_classes)\n",
    "net.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4ZlA9JkUOIg",
    "outputId": "2660d403-8299-4f38-ce40-590fa165ed9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 1.6473338603973389\n",
      "Epoch: 1 | Training Loss: 1.57392418384552\n",
      "Epoch: 2 | Training Loss: 1.5211838483810425\n",
      "Epoch: 3 | Training Loss: 1.4879330396652222\n",
      "Epoch: 4 | Training Loss: 1.470410704612732\n",
      "Epoch: 5 | Training Loss: 1.4631627798080444\n",
      "Epoch: 6 | Training Loss: 1.460853934288025\n",
      "Epoch: 7 | Training Loss: 1.4595469236373901\n",
      "Epoch: 8 | Training Loss: 1.4569655656814575\n",
      "Epoch: 9 | Training Loss: 1.452209711074829\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    # Loop over all batches\n",
    "    for x, y in train_dl:\n",
    "        optimizer.zero_grad()  # zero the gradient buffer.\n",
    "        \n",
    "        conversation, category = Variable(x), Variable(y)\n",
    "                \n",
    "        #Transposing the training data.\n",
    "        conversation = conversation.t()\n",
    "        \n",
    "        outputs = net(conversation.to(device))\n",
    "        \n",
    "        # Note: The true category tensor has to always be a 1D tensor of values (labels) for CrossEntropy!\n",
    "        loss = criterion(outputs.to(device), category.squeeze().long().to(device)) \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch} | Training Loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 40.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1331 test articles: 19.459053343350863 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "net.eval()\n",
    "\n",
    "test_preds = []\n",
    "true = []\n",
    "\n",
    "for x, y in tqdm(test_dl):\n",
    "    conversation, category = Variable(x), Variable(y)\n",
    "    conversation = conversation.t()\n",
    "    preds = net(conversation.to(device))\n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    test_preds.extend(predicted.tolist())\n",
    "    true.extend(y.squeeze().long().tolist())\n",
    "\n",
    "total = len(true)\n",
    "correct = 0\n",
    "for i in range(total):\n",
    "    if test_preds[i] == true[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test articles: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Classification_PyTorch_v1(incomplete-currently_working)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
